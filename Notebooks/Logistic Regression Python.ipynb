{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb6a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba5a5830",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/media/kwa/Data Disk/home/kwa/Projects/corpora/aclImdb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "943045b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this variable to a number to be used as the random seed\n",
    "# or to None if you don't want to set a random seed\n",
    "seed = 1234\n",
    "\n",
    "if seed is not None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a0ebc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positive reviews: 12500\n",
      "number of negative reviews: 12500\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "pos_files = glob(base_dir + 'train/pos/*.txt')\n",
    "neg_files = glob(base_dir + 'train/neg/*.txt')\n",
    "\n",
    "print('number of positive reviews:', len(pos_files))\n",
    "print('number of negative reviews:', len(neg_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a1af83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3445861 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# initialize CountVectorizer indicating that we will give it a list of filenames that have to be read\n",
    "cv = CountVectorizer(input='filename')\n",
    "\n",
    "# learn vocabulary and return sparse document-term matrix\n",
    "doc_term_matrix = cv.fit_transform(pos_files + neg_files)\n",
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab07589c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 74849)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = doc_term_matrix.toarray()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6035d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training labels\n",
    "y_pos = np.ones(len(pos_files))\n",
    "y_neg = np.zeros(len(neg_files))\n",
    "y_train = np.concatenate([y_pos, y_neg])\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e08f9adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples, n_features = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63a15e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d13462fd69459a979ebce9202f5055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 1:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd777a0f8ac448b49f853a5e40f30765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 2:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77df138c8cea4e6b966314940301f7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 3:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5075511d3a1045ef8a0256bfaac86297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 4:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62ed8cae1ab4ac6b9326bdffb0ae802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 5:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3910c8b909453da59520556603f773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 6:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6a46a9455b424c9e39c1a042df497c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 7:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f15b707ae44aa1a011199b99d93596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 8:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54dd8fe6bf44404fb4f58b1f336cb5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 9:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383468ca667343d1807e8e0eccfe1033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 10:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 10\n",
    "\n",
    "model = nn.Linear(n_features, 1)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "indices = np.arange(n_examples)\n",
    "for epoch in range(n_epochs):\n",
    "    # n_errors = 0\n",
    "    # randomize training examples\n",
    "    np.random.shuffle(indices)\n",
    "    # for each training example\n",
    "    for i in tqdm(indices, desc=f'epoch {epoch+1}'):\n",
    "        x = X_train[i]\n",
    "        y_true = y_train[i]\n",
    "        # make predictions\n",
    "        y_pred = model(x)\n",
    "        # calculate loss\n",
    "        loss = loss_func(y_pred[0], y_true)\n",
    "        # calculate gradients through back-propagation\n",
    "        loss.backward()\n",
    "        # optimize model parameters\n",
    "        optimizer.step()\n",
    "        # ensure gradients are set to zero\n",
    "        model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "552c2bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_files = glob(base_dir + 'test/pos/*.txt')\n",
    "neg_files = glob(base_dir + 'test/neg/*.txt')\n",
    "doc_term_matrix = cv.transform(pos_files + neg_files)\n",
    "X_test = doc_term_matrix.toarray()\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_pos = np.ones(len(pos_files))\n",
    "y_neg = np.zeros(len(neg_files))\n",
    "y_test = np.concatenate([y_pos, y_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e46dad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_test) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42271717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classification_report(y_true, y_pred):\n",
    "    # count true positives, false positives, true negatives, and false negatives\n",
    "    tp = fp = tn = fn = 0\n",
    "    for gold, pred in zip(y_true, y_pred):\n",
    "        if pred == True:\n",
    "            if gold == True:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            if gold == False:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "    # calculate precision and recall\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    # calculate f1 score\n",
    "    fscore = 2 * precision * recall / (precision + recall)\n",
    "    # calculate accuracy\n",
    "    accuracy = (tp + tn) / len(y_true)\n",
    "    # number of positive labels in y_true\n",
    "    support = sum(y_true)\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1-score\": fscore,\n",
    "        \"support\": support,\n",
    "        \"accuracy\": accuracy,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84666c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.7526381909547739, 'recall': 0.95856, 'f1-score': 0.8432090077410275, 'support': 12500.0, 'accuracy': 0.82176}\n"
     ]
    }
   ],
   "source": [
    "print(binary_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d23632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
